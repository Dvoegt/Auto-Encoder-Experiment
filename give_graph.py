import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from statistics import mean 
from scipy import stats
import numpy as np


# Data for Bayes on Fashion 
'''
learning_rates = [0.000991604271294348, 0.0010004828261480328, 0.0037478898397911723, 0.00036010164719848804, 0.0010725957237933, 0.0049380537259342125, 0.0017638184720001448, 0.0024371643025337037, 0.0002500734686529184, 0.00411146755250019, 0.008940095257316996, 0.00016173771404211156, 0.00010640396426483044, 0.0005372277801995, 0.0001005553103566813, 0.0007093486875794122, 0.00020485711120716757, 0.00031206676019058773]
trials = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]

loss_values = [0.5978, 0.6061, 0.6888, 0.5986, 0.5897, 
               0.693, 0.6252, 0.6019, 0.5978, 1.1151,
                 0.7053, 0.5936, 0.6057, 0.5969, 0.6122,
                   0.5992, 0.5854, 0.5983,0.598, 0.598]

epoch_rate = [12, 18, 24, 19, 21, 10, 22, 25, 22, 12, 28, 29, 27, 30, 20, 30, 17, 16]
batch_size = [113, 218, 105, 187, 214, 255, 31, 236, 199, 16, 164, 192, 153, 185, 122, 223, 80, 73]

'''




#Data for Bayes on standard
loss_values = [0.9010, 0.9012, 0.8563, 0.9304, 0.9216, 0.8937, 0.9296, 0.9195, 0.9222, 0.8834, 0.8328, 0.8459, 0.8409, 0.8664, 0.8578, 0.9194, 0.8833, 0.8974, 0.9245, 0.8723]
epoch_rate = [11, 13, 10, 11, 14, 10, 16, 10, 12, 14, 19, 19, 25, 23, 16, 22, 21, 14, 17, 17]
learning_rate = [0.000141554353732431, 0.00010138687240570748, 0.00013305169687523476, 0.0024021714148934783, 0.00014006889073895991, 0.00020202022514789118, 0.006127834794801622, 0.000989571402251018, 0.0009975557477861494, 0.0005178910812130591, 0.0003414510956546249, 0.000330185325454978, 0.0003607152305596876, 0.000414587732401141, 0.0005523634686391063, 0.00024323481424154544, 0.0006684190452634027, 0.0015444471614392266, 0.0003720142546280293, 0.00037340366588216024]
trials = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
batch_size = [125, 152, 31, 77, 226, 125, 98, 129, 95, 178, 31, 26, 24, 256, 16, 54, 190, 79, 98, 125]
average_loss = mean(loss_values)
#0.89
last5_loss = mean(loss_values[-5:])
#0.90
print(last5_loss)
first5_loss = mean(loss_values[0:5])
#0.90
print(first5_loss)

indexs = []
for i in learning_rate: 
    if i <= 0.00075:
        indexs.append(learning_rate.index(i))

l_values = []
for i in indexs:
    l_values.append(loss_values[i])

variance = np.var(l_values)
my_mean = mean(l_values)
print('v',variance)
print('m',my_mean)


'''
#Data for CMA-ES Fashion MNIST
learning_rate = [0.0004888347338489608, 0.0015628173714400469, 0.001671261492978042, 0.0006209655660881149, 0.0014287654647515094, 0.0028028778095218225, 0.0013379341615535802, 0.0012468457163977748, 0.0005730156017126731, 0.00030282071942595325, 0.0032433339760720857, 0.0005706588224269069, 0.0008610874424292367, 0.0013603088433894574, 0.00019563185965284493, 0.001002083722600216, 0.001047510229454436, 0.00043376463874378004, 0.0009994660903947582, 0.0016778330333662734]
epoch_rate = [10, 17, 16, 16, 15, 11, 17, 15, 19, 20, 10, 15, 14, 16, 17, 14, 12, 15, 10, 14]
batch_size = [70, 64, 82, 176, 113, 55, 142, 114, 63, 185, 49, 122, 91, 132, 34, 93, 103, 59, 98, 32]
loss_values = [0.5738019347190857, 0.5985580086708069, 0.5865185260772705, 0.5811687111854553, 0.6012411713600159, 0.5743589997291565, 0.5782168507575989, 0.5761773586273193, 0.5613137483596802, 0.5982349514961243, 0.7031395435333252, 0.5646653175354004, 0.6018579602241516, 0.5868955254554749, 0.6271843910217285, 0.5832211375236511, 0.5998172163963318, 0.5756512880325317, 0.5853371620178223, 0.600176990032196]
trials = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
'''


'''
#CMA-ES Standard MNIST
batch_sizes = [65, 95, 122, 156, 165, 131, 197, 190, 118, 174, 149, 165, 157, 131, 197, 190, 118, 174, 173, 176]

epoch_rates = [12, 13, 18, 17, 23, 19, 14, 15, 20, 13, 16, 18, 14, 15, 20, 13, 11, 16, 11, 10]

learning_rate = [
    0.0009933795697043423, 0.0012318916250075693, 0.0009128268409195405, 0.001242322507890372, 0.002155322301673608,
    0.000425929285279424, 0.0009350622401507852, 0.00043839663846044816, 0.00031122804160121123, 0.0003068240934065875,
    0.0006318298193780592, 0.00021960631807346, 0.00038377064530673087, 0.00043839663846044816, 0.00031122804160121123,
    0.0003068240934065875, 0.00021960631807346, 0.00038377064530673087, 0.0005264933221401165, 0.0005172147748830711
]

loss_values = [
    0.9232945442199707, 0.9253758788108826, 0.9254539012908936, 0.9237775206565857, 0.9248148798942566,
    0.8768607974052429, 0.9250799417495728, 0.8853347301483154, 0.8808013200759888, 0.8654235601425171,
    0.8690735101699829, 0.8769482970237732, 0.8889737725257874, 0.9259669780731201, 0.8952273726463318,
    0.8691994547843933, 0.8648472428321838, 0.8782798051834106, 0.8788653016090393, 0.9256300926208496
]
trials = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]

average_loss = mean(loss_values)
#0.90
last5_loss = mean(loss_values[-5:])
#0.88
print(last5_loss)
first5_loss = mean(loss_values[0:5])
#0.92
print(first5_loss)
'''


'''
print(len(loss_values))
print(len(learning_rate))

# Create the dot plot
plt.figure(figsize=(8, 6))
plt.scatter(epoch_rates, loss_values, marker='o')
plt.title('Epoch rate vs Loss')
plt.xlabel('Epoch rate')
plt.ylabel('Loss')
plt.grid(True)
plt.show()
'''



'''
# Define the datasets
method_a = [0.9233, 0.9254, 0.9254, 0.9238, 0.9248, 0.8769, 0.9251, 0.8853, 0.8808, 0.8654, 0.8691, 0.8769, 0.8890, 0.9260, 0.8952, 0.8692, 0.8648, 0.8783, 0.8789, 0.9256]
method_b = [0.9010, 0.9012, 0.8563, 0.9304, 0.9216, 0.8937, 0.9296, 0.9195, 0.9222, 0.8834, 0.8328, 0.8459, 0.8409, 0.8664, 0.8578, 0.9194, 0.8833, 0.8974, 0.9245, 0.8723]
method_a = method_a[0:5]
method_b = method_b[0:5]
# Perform two-sample t-test
t_stat, p_value = stats.ttest_ind(method_a, method_b)
print('t_stat : ',t_stat)
print('p_value',p_value)
'''